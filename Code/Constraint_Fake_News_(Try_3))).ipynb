{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Constraint-Fake News-(Try 3)))",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcmE1FLhS9PE",
        "outputId": "dcdf2521-9c6d-44ed-ea66-fe20a144a678"
      },
      "source": [
        "%%time\r\n",
        "import os\r\n",
        "from glob import glob\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "import json\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import regularizers\r\n",
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "from tensorflow.keras.layers import LSTM,GRU\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.metrics import classification_report \r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\r\n",
        "from sklearn.metrics import average_precision_score,roc_auc_score, roc_curve, precision_recall_curve\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.26 ms, sys: 16 µs, total: 1.28 ms\n",
            "Wall time: 1.29 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2tKLhTotZOV",
        "outputId": "a6d33f4b-98e9-44ea-846a-5d922c7984ae"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 359
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-isPOTqtIu2"
      },
      "source": [
        "stops = set(stopwords.words(\"english\"))\r\n",
        "def cleantext(string):\r\n",
        "    text = string.lower().split()\r\n",
        "    text = \" \".join(text)\r\n",
        "    text = re.sub(r\"http(\\S)+\",' ',text)    \r\n",
        "    text = re.sub(r\"www(\\S)+\",' ',text)\r\n",
        "    text = re.sub(r\"&\",' and ',text)  \r\n",
        "    tx = text.replace('&amp',' ')\r\n",
        "    text = re.sub(r\"[^0-9a-zA-Z]+\",' ',text)\r\n",
        "    text = text.split()\r\n",
        "    text = [w for w in text if not w in stops]\r\n",
        "    text = \" \".join(text)\r\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGXpNuzWSfb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1116bc5f-4bd4-4705-f066-ba90112e95d6"
      },
      "source": [
        "%%time\n",
        "path = \"/content/drive/My Drive/SharedTasksParticipation/SharedTask@Constraint@AAAI2021/\"\n",
        "train_filename= path + \"Constraint_English_Train.xlsx\"\n",
        "val_filename = path + \"Constraint_English_Val.xlsx\"\n",
        "test_filename = path + \"Constraint_English_Test.xlsx\"\n",
        "\n",
        "train = pd.read_excel(train_filename)\n",
        "val = pd.read_excel(val_filename)\n",
        "test = pd.read_excel(test_filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 294 ms, sys: 1.54 ms, total: 296 ms\n",
            "Wall time: 305 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS7BJPDiY3gr"
      },
      "source": [
        "train['train_label']= train.label.replace({'real':0,'fake':1})\r\n",
        "val['val_label']= val.label.replace({'real':0,'fake':1})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRNut988y1u9"
      },
      "source": [
        "train['cleaned'] = train['tweet'].map(lambda x: cleantext(x))\r\n",
        "val['cleaned'] = val['tweet'].map(lambda x: cleantext(x))\r\n",
        "test['cleaned'] = test['tweet'].map(lambda x: cleantext(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXFGFQsDQSLt"
      },
      "source": [
        "total_data=pd.concat([train.cleaned, val.cleaned, test.cleaned], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "L32nDPntRtyO",
        "outputId": "dc5b96fc-49f9-46d1-8484-63a652248384"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>train_label</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
              "      <td>real</td>\n",
              "      <td>0</td>\n",
              "      <td>cdc currently reports 99031 deaths general dis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>States reported 1121 deaths a small rise from ...</td>\n",
              "      <td>real</td>\n",
              "      <td>0</td>\n",
              "      <td>states reported 1121 deaths small rise last tu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>politically correct woman almost uses pandemic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
              "      <td>real</td>\n",
              "      <td>0</td>\n",
              "      <td>indiafightscorona 1524 covid testing laborator...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Populous states can generate large case counts...</td>\n",
              "      <td>real</td>\n",
              "      <td>0</td>\n",
              "      <td>populous states generate large case counts loo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6415</th>\n",
              "      <td>6416</td>\n",
              "      <td>A tiger tested positive for COVID-19 please st...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>tiger tested positive covid 19 please stay awa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6416</th>\n",
              "      <td>6417</td>\n",
              "      <td>???Autopsies prove that COVID-19 is??� a blood...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>autopsies prove covid 19 blood clot pneumonia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6417</th>\n",
              "      <td>6418</td>\n",
              "      <td>_A post claims a COVID-19 vaccine has already ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>post claims covid 19 vaccine already developed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6418</th>\n",
              "      <td>6419</td>\n",
              "      <td>Aamir Khan Donate 250 Cr. In PM Relief Cares Fund</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>aamir khan donate 250 cr pm relief cares fund</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6419</th>\n",
              "      <td>6420</td>\n",
              "      <td>It has been 93 days since the last case of COV...</td>\n",
              "      <td>real</td>\n",
              "      <td>0</td>\n",
              "      <td>93 days since last case covid 19 acquired loca...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6420 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                            cleaned\n",
              "0        1  ...  cdc currently reports 99031 deaths general dis...\n",
              "1        2  ...  states reported 1121 deaths small rise last tu...\n",
              "2        3  ...  politically correct woman almost uses pandemic...\n",
              "3        4  ...  indiafightscorona 1524 covid testing laborator...\n",
              "4        5  ...  populous states generate large case counts loo...\n",
              "...    ...  ...                                                ...\n",
              "6415  6416  ...  tiger tested positive covid 19 please stay awa...\n",
              "6416  6417  ...  autopsies prove covid 19 blood clot pneumonia ...\n",
              "6417  6418  ...  post claims covid 19 vaccine already developed...\n",
              "6418  6419  ...      aamir khan donate 250 cr pm relief cares fund\n",
              "6419  6420  ...  93 days since last case covid 19 acquired loca...\n",
              "\n",
              "[6420 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 396
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "_6QyyBkVR7gm",
        "outputId": "8f162eba-c768-4ffd-a281-75900039730b"
      },
      "source": [
        "val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>val_label</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Chinese converting to Islam after realising th...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>chinese converting islam realising muslim affe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>11 out of 13 people (from the Diamond Princess...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>11 13 people diamond princess cruise ship inti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>COVID-19 Is Caused By A Bacterium, Not Virus A...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>covid 19 caused bacterium virus treated aspirin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Mike Pence in RNC speech praises Donald Trump’...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>mike pence rnc speech praises donald trump cov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>6/10 Sky's @EdConwaySky explains the latest #C...</td>\n",
              "      <td>real</td>\n",
              "      <td>0</td>\n",
              "      <td>6 10 sky edconwaysky explains latest covid19 d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2135</th>\n",
              "      <td>2136</td>\n",
              "      <td>Donald Trump wrongly claimed that New Zealand ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>donald trump wrongly claimed new zealand big s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2136</th>\n",
              "      <td>2137</td>\n",
              "      <td>Current understanding is #COVID19 spreads most...</td>\n",
              "      <td>real</td>\n",
              "      <td>0</td>\n",
              "      <td>current understanding covid19 spreads mostly p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2137</th>\n",
              "      <td>2138</td>\n",
              "      <td>Nothing screams “I am sat around doing fuck al...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>nothing screams sat around fuck lockdown quite...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2138</th>\n",
              "      <td>2139</td>\n",
              "      <td>Birx says COVID-19 outbreak not under control ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>birx says covid 19 outbreak control people move</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2139</th>\n",
              "      <td>2140</td>\n",
              "      <td>Another 4422 new coronavirus cases have been c...</td>\n",
              "      <td>real</td>\n",
              "      <td>0</td>\n",
              "      <td>another 4422 new coronavirus cases confirmed u...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2140 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                            cleaned\n",
              "0        1  ...  chinese converting islam realising muslim affe...\n",
              "1        2  ...  11 13 people diamond princess cruise ship inti...\n",
              "2        3  ...    covid 19 caused bacterium virus treated aspirin\n",
              "3        4  ...  mike pence rnc speech praises donald trump cov...\n",
              "4        5  ...  6 10 sky edconwaysky explains latest covid19 d...\n",
              "...    ...  ...                                                ...\n",
              "2135  2136  ...  donald trump wrongly claimed new zealand big s...\n",
              "2136  2137  ...  current understanding covid19 spreads mostly p...\n",
              "2137  2138  ...  nothing screams sat around fuck lockdown quite...\n",
              "2138  2139  ...    birx says covid 19 outbreak control people move\n",
              "2139  2140  ...  another 4422 new coronavirus cases confirmed u...\n",
              "\n",
              "[2140 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 398
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "L5QTGRdwR1M4",
        "outputId": "07e4d3de-825f-4e84-97db-185d2c4769fc"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Our daily update is published. States reported...</td>\n",
              "      <td>daily update published states reported 734k te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Alfalfa is the only cure for COVID-19.</td>\n",
              "      <td>alfalfa cure covid 19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>President Trump Asked What He Would Do If He W...</td>\n",
              "      <td>president trump asked would catch coronavirus ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>States reported 630 deaths. We are still seein...</td>\n",
              "      <td>states reported 630 deaths still seeing solid ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>This is the sixth time a global health emergen...</td>\n",
              "      <td>sixth time global health emergency declared in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2135</th>\n",
              "      <td>2136</td>\n",
              "      <td>#CoronaVirusUpdates: State-wise details of Tot...</td>\n",
              "      <td>coronavirusupdates state wise details total co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2136</th>\n",
              "      <td>2137</td>\n",
              "      <td>Tonight 12(midnight) onwards Disaster Manageme...</td>\n",
              "      <td>tonight 12 midnight onwards disaster managemen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2137</th>\n",
              "      <td>2138</td>\n",
              "      <td>296 new cases of #COVID19Nigeria; Plateau-85 E...</td>\n",
              "      <td>296 new cases covid19nigeria plateau 85 enugu ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2138</th>\n",
              "      <td>2139</td>\n",
              "      <td>RT @CDCemergency: #DYK? @CDCgov’s One-Stop Sho...</td>\n",
              "      <td>rt cdcemergency dyk cdcgov one stop shop covid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2139</th>\n",
              "      <td>2140</td>\n",
              "      <td>More than half of pregnant women recently admi...</td>\n",
              "      <td>half pregnant women recently admitted uk hospi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2140 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                            cleaned\n",
              "0        1  ...  daily update published states reported 734k te...\n",
              "1        2  ...                              alfalfa cure covid 19\n",
              "2        3  ...  president trump asked would catch coronavirus ...\n",
              "3        4  ...  states reported 630 deaths still seeing solid ...\n",
              "4        5  ...  sixth time global health emergency declared in...\n",
              "...    ...  ...                                                ...\n",
              "2135  2136  ...  coronavirusupdates state wise details total co...\n",
              "2136  2137  ...  tonight 12 midnight onwards disaster managemen...\n",
              "2137  2138  ...  296 new cases covid19nigeria plateau 85 enugu ...\n",
              "2138  2139  ...  rt cdcemergency dyk cdcgov one stop shop covid...\n",
              "2139  2140  ...  half pregnant women recently admitted uk hospi...\n",
              "\n",
              "[2140 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 397
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fVjKbA2SG5P",
        "outputId": "8298a736-8988-41d2-f3c2-2c488f8a4d9e"
      },
      "source": [
        "total_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       cdc currently reports 99031 deaths general dis...\n",
              "1       states reported 1121 deaths small rise last tu...\n",
              "2       politically correct woman almost uses pandemic...\n",
              "3       indiafightscorona 1524 covid testing laborator...\n",
              "4       populous states generate large case counts loo...\n",
              "                              ...                        \n",
              "2135    coronavirusupdates state wise details total co...\n",
              "2136    tonight 12 midnight onwards disaster managemen...\n",
              "2137    296 new cases covid19nigeria plateau 85 enugu ...\n",
              "2138    rt cdcemergency dyk cdcgov one stop shop covid...\n",
              "2139    half pregnant women recently admitted uk hospi...\n",
              "Name: cleaned, Length: 10700, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 399
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1Ni0qZwTivJ"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "\r\n",
        "def text_encoding(texts, labels, padding_length):\r\n",
        "  tokenizer = Tokenizer()\r\n",
        "  \r\n",
        "  # Tokenizer is fitted into the texts\r\n",
        "  tokenizer.fit_on_texts(texts)\r\n",
        "\r\n",
        "  # Encoding texts into integer sequences\r\n",
        "  sequences = tokenizer.texts_to_sequences(texts)\r\n",
        "  # Pad sequences\r\n",
        "  corpus = keras.preprocessing.sequence.pad_sequences(sequences, value=0.0,\r\n",
        "                                                      padding='post', maxlen= padding_length)\r\n",
        "\r\n",
        "  return corpus, labels, tokenizer\r\n",
        "\r\n",
        "##\r\n",
        "#max_words = 20000 # Based on number of unique words in the dataset\r\n",
        "padding_length = 100\r\n",
        "corpus, labels, tokenizer = text_encoding(total_data, train.train_label, padding_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3Lsr4R6UKUu"
      },
      "source": [
        "train_data, train_labels = corpus, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKA7w7SkUh5q",
        "outputId": "ceeae9dc-d4b7-4525-e88b-46244d54dc4b"
      },
      "source": [
        "print(training_data, training_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  69  215  203 ...    0    0    0]\n",
            " [  12   18 6790 ...    0    0    0]\n",
            " [4792 1770  373 ...    0    0    0]\n",
            " ...\n",
            " [ 216  104    1 ...    0    0    0]\n",
            " [2806  899 2685 ...    0    0    0]\n",
            " [1560   42   83 ...    0    0    0]] [0 0 1 ... 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAHPN3Mb_rmq",
        "outputId": "9d96317a-bb68-412e-f137-0049642e51b9"
      },
      "source": [
        "word_index = tokenizer.word_index\r\n",
        "vocab_size = len(tokenizer.word_index) + 1\r\n",
        "print(\"Vocabulary Size :\", vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size : 18243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "UG-QHxaN6dma",
        "outputId": "df27475c-2bfd-41d6-ecc1-214e451dc775"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\r\n",
        "!unzip glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-10 10:47:25--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-12-10 10:47:25--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-12-10 10:47:25--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1        7%[>                   ]  64.80M  8.29MB/s    eta 91s    ^C\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-377-6288f7ed8be8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget http://nlp.stanford.edu/data/glove.6B.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unzip glove.6B.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m   result = _run_command(\n\u001b[0;32m--> 440\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    441\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    189\u001b[0m           \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m           \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m           close_fds=True)\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;31m# The child PTY is only needed by the spawned process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    727\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1316\u001b[0m                 \u001b[0merrpipe_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m                     \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrpipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m                     \u001b[0merrpipe_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrpipe_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbRMnAxP6hH3",
        "outputId": "b64ff1a1-9ccd-440c-f921-ac0b962897b3"
      },
      "source": [
        "GLOVE_EMB = '/content/glove.6B.100d.txt'\r\n",
        "\r\n",
        "embeddings_index = {}\r\n",
        "\r\n",
        "f = open(GLOVE_EMB)\r\n",
        "for line in f:\r\n",
        "  values = line.split()\r\n",
        "  word = value = values[0]\r\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\r\n",
        "  embeddings_index[word] = coefs\r\n",
        "f.close()\r\n",
        "\r\n",
        "print('Found %s word vectors.' %len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAbRCUaO_f_K"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 100))\r\n",
        "for word, i in word_index.items():\r\n",
        "  embedding_vector = embeddings_index.get(word)\r\n",
        "  if embedding_vector is not None:\r\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn1ZqKr0VLly"
      },
      "source": [
        "## Defining Callbacks\r\n",
        "def define_callback():\r\n",
        "  keras.backend.clear_session()\r\n",
        "  accuracy_threshold = .9999\r\n",
        "\r\n",
        "  class myCallback(keras.callbacks.Callback):\r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        if(logs.get('accuracy')>accuracy_threshold):\r\n",
        "          print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\r\n",
        "          self.model.stop_training = True\r\n",
        "\r\n",
        "  acc_callback = myCallback()\r\n",
        "\r\n",
        "  return acc_callback\r\n",
        "\r\n",
        "# Define Checkpoint\r\n",
        "def define_checkpoint():\r\n",
        "  filepath = \"ModelOnOurData.h5\"\r\n",
        "  checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True, save_weights_only=False, mode='max')\r\n",
        "  return checkpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbjBnr2eVwbI"
      },
      "source": [
        "from tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, Dropout\r\n",
        "from tensorflow.keras.layers import SpatialDropout1D\r\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA-QcHtcVVPb"
      },
      "source": [
        "# Create Model\r\n",
        "def create_model(embedding_dim):\r\n",
        "  keras.backend.clear_session()\r\n",
        "\r\n",
        "  model = keras.models.Sequential([\r\n",
        "      keras.layers.Embedding(vocab_size, embedding_dim, input_length = padding_length),\r\n",
        "      #keras.layers.Conv1D(64, 5, activation='relu'),\r\n",
        "      #keras.layers.MaxPooling1D(5),\r\n",
        "      #keras.layers.Bidirectional(LSTM(32, dropout=0.4)),\r\n",
        "      #keras.layers.Dense(64, activation='relu'),\r\n",
        "      #keras.layers.Dropout(0.5),\r\n",
        "      keras.layers.Dense(64, activation='relu'),\r\n",
        "      keras.layers.Flatten(),\r\n",
        "      keras.layers.Dense(2, activation = 'softmax')\r\n",
        "  ])\r\n",
        "\r\n",
        "  model.summary()\r\n",
        "  return model\r\n",
        "\r\n",
        "\r\n",
        "# Compile Model\r\n",
        "def compile_model(model):\r\n",
        "  model.compile(optimizer=Adam(learning_rate=0.0001),\r\n",
        "                  loss='sparse_categorical_crossentropy',\r\n",
        "                  metrics='accuracy')\r\n",
        "  return model\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kQw1ayAXFbo",
        "outputId": "eb1a99c6-46f6-41d6-a4f4-482f86cea5c5"
      },
      "source": [
        "%%time\r\n",
        "## Callbacks are really important \r\n",
        "\r\n",
        "def run_callback_list():\r\n",
        "  acc_callback = define_callback()\r\n",
        "  checkpoint = define_checkpoint()\r\n",
        "  return [acc_callback, checkpoint] \r\n",
        "\r\n",
        "callback_list = run_callback_list()\r\n",
        "\r\n",
        "def run_model():\r\n",
        "    embedding_dim = 100\r\n",
        "    model = create_model(embedding_dim)\r\n",
        "    model = compile_model(model)\r\n",
        "    return model\r\n",
        "\r\n",
        "## Create, Compile and Visualize the model\r\n",
        "cnn_lstm_model = run_model() ## "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 100)          1824300   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100, 64)           6464      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 12802     \n",
            "=================================================================\n",
            "Total params: 1,843,566\n",
            "Trainable params: 1,843,566\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 70.9 ms, sys: 2.21 ms, total: 73.1 ms\n",
            "Wall time: 60.4 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukDreeN2CFJF"
      },
      "source": [
        "cnn_lstm_model.layers[0].set_weights([embedding_matrix])\r\n",
        "cnn_lstm_model.layers[0].trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "2Ej4j7KCYSdX",
        "outputId": "336471d5-9c9c-4623-a3ea-95ef4c116e2f"
      },
      "source": [
        "cnn_lstm_model_history = cnn_lstm_model.fit(train_data,\r\n",
        "                              train_labels,\r\n",
        "                              epochs = 50,\r\n",
        "                              batch_size = 64,\r\n",
        "                              verbose = 1,\r\n",
        "                              validation_split = 0.15,\r\n",
        "                              callbacks = callback_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-410-ab5547d85de5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                               callbacks = callback_list)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[1;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 9095\n  y sizes: 6420\nPlease provide data which shares the same first dimension."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l2-n0Mg_Kjf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcyXEMxC2kJE",
        "outputId": "aafa451d-2c8a-41e3-d54e-cf4029a1b6e3"
      },
      "source": [
        "val_sequences = tokenizer.texts_to_sequences(val.cleaned)\r\n",
        "print(val_sequences[0:10])\r\n",
        "val_data = keras.preprocessing.sequence.pad_sequences(val_sequences, value=0.0,\r\n",
        "                                                      padding='post', maxlen= padding_length)\r\n",
        "val_labels = val['val_label']\r\n",
        "\r\n",
        "print(val_data[:5], val_data.shape)\r\n",
        "print(val_labels[:5], val_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[234, 9592, 4338, 828, 424, 4, 73], [106, 239, 8, 5084, 3991, 1683, 1347, 41, 236, 9, 1116, 1126, 16, 40, 346, 12], [1, 2, 392, 2526, 29, 859, 5044], [2014, 2032, 7757, 4078, 10896, 178, 43, 1, 2, 3937, 2174, 1010, 2457, 68, 23, 3636], [55, 63, 968, 1053, 110, 5, 38, 67, 2639, 77, 4, 38], [24, 1515, 135, 66, 959, 374, 851, 236, 44, 1971, 44, 1799, 637, 311, 42, 298, 3796, 3877, 2468, 4320, 5694], [27, 7, 24, 449, 5, 575, 1375, 290, 13, 31, 445, 57, 502, 6074, 75, 66, 17, 339, 371, 204, 122, 12, 375, 1700, 416, 156, 132], [39, 5, 297, 10464, 4462, 2419, 260, 166, 111, 8, 3791], [70, 262, 6100, 1111, 5572, 257, 931, 2911, 18, 1588, 2084, 315, 107, 3914, 2809, 248, 75], [2497, 448, 2176, 2420, 35, 284, 301]]\n",
            "[[  234  9592  4338   828   424     4    73     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]\n",
            " [  106   239     8  5084  3991  1683  1347    41   236     9  1116  1126\n",
            "     16    40   346    12     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]\n",
            " [    1     2   392  2526    29   859  5044     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]\n",
            " [ 2014  2032  7757  4078 10896   178    43     1     2  3937  2174  1010\n",
            "   2457    68    23  3636     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]\n",
            " [   55    63   968  1053   110     5    38    67  2639    77     4    38\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]] (2140, 100)\n",
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: val_label, dtype: int64 (2140,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdJckS8juG3F",
        "outputId": "b11cdd8d-6aa1-4d79-8fd4-ae202553f3bf"
      },
      "source": [
        "cnn_lstm_model=load_model(\"/content/ModelOnOurData.h5\")\r\n",
        "val_ls, val_acc = cnn_lstm_model.evaluate(val_data, val_labels)\r\n",
        "print(val_labels)\r\n",
        "print(val_ls, val_acc)\r\n",
        "pred = np.argmax(cnn_lstm_model.predict(val_data), axis=-1)\r\n",
        "print(pred)\r\n",
        "print_metrices(pred, val_labels)\r\n",
        "#plot_confusion_matrix(confusion_matrix(val['label'],pred),target_names=['real','fake'], normalize = False, \\\r\n",
        "                      #title = 'Confusion matix of SVM on val data')\r\n",
        "\r\n",
        "\r\n",
        "#svm_val_misclass_df = val_ori[pred!=val['label']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.5262\n",
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       0\n",
            "       ..\n",
            "2135    1\n",
            "2136    0\n",
            "2137    1\n",
            "2138    1\n",
            "2139    0\n",
            "Name: val_label, Length: 2140, dtype: int64\n",
            "0.2093476951122284 0.5261682271957397\n",
            "[1 0 1 ... 1 1 0]\n",
            "[[1040   80]\n",
            " [  86  934]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.93      0.93      1120\n",
            "           1       0.92      0.92      0.92      1020\n",
            "\n",
            "    accuracy                           0.92      2140\n",
            "   macro avg       0.92      0.92      0.92      2140\n",
            "weighted avg       0.92      0.92      0.92      2140\n",
            "\n",
            "Accuracy :  0.922429906542056\n",
            "Precison :  0.9224660331422289\n",
            "Recall :  0.922429906542056\n",
            "F1 :  0.9224407057208079\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaW6HiKJPN7f"
      },
      "source": [
        "# Prediction on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdcsqpM9LNIV",
        "outputId": "cb1f3c9b-447e-4f7a-d926-d52338382fed"
      },
      "source": [
        "test_sequences = tokenizer.texts_to_sequences(test.cleaned)\r\n",
        "print(test_sequences[0:10])\r\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_sequences, value=0.0,\r\n",
        "                                                      padding='post', maxlen= padding_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[48, 34, 97, 12, 18, 9, 8531, 6, 3, 9714, 10, 251, 223, 1386, 2716, 80, 86, 83, 298, 406], [134, 1, 2], [68, 43, 633, 164, 2397, 4, 309, 4], [12, 18, 10, 113, 1415, 1972, 156, 984, 79, 105, 1879, 3011, 311, 42, 1649, 1530, 316, 69, 1498, 1692, 1879, 127, 86, 30, 79, 105, 1191], [3631, 86, 328, 20, 437, 1532, 535, 20, 2547, 1918, 354, 141], [292, 7603, 3401, 1562, 32, 1, 2], [704, 1785, 493, 3711, 84, 1948, 251, 3711, 84, 12, 25, 251, 12, 25, 493, 1540, 10360, 23, 493, 5099, 251], [67, 1692, 351, 6, 156, 52, 693, 3735, 1706, 35, 2200, 539, 1208], [48, 34, 97, 310, 13, 81, 61, 9, 62, 18, 183, 83, 139, 11, 214, 180, 9, 23, 203, 12, 25, 9, 53], [576, 19, 37, 536, 2824, 2100, 1287, 17, 20, 295, 228, 2604, 945, 1287, 4115, 17, 13, 9167, 1405, 687, 236, 9, 855, 251, 4115, 13085, 926, 17, 2491, 261, 236]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir0R6mpKMdPd"
      },
      "source": [
        "pred= np.argmax(cnn_lstm_model.predict(test_data), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZebMSV6sNMrC"
      },
      "source": [
        "jongu = pd.DataFrame(pred, columns=['ll'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "YRKZW2wiNdRQ",
        "outputId": "58d7907e-7544-4567-ff46-66328ffd3416"
      },
      "source": [
        "jongu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ll</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2135</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2136</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2137</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2138</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2139</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2140 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      ll\n",
              "0      0\n",
              "1      1\n",
              "2      1\n",
              "3      0\n",
              "4      0\n",
              "...   ..\n",
              "2135   0\n",
              "2136   0\n",
              "2137   0\n",
              "2138   0\n",
              "2139   1\n",
              "\n",
              "[2140 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 350
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EhTUvIRMoMf"
      },
      "source": [
        "test['label']= jongu.ll.replace({0:'real',1:'fake'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "fRDSrB3rNKam",
        "outputId": "6ef06cab-3768-47a6-8835-ab05ca2cf36e"
      },
      "source": [
        "test.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Our daily update is published. States reported...</td>\n",
              "      <td>daily update published states reported 734k te...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Alfalfa is the only cure for COVID-19.</td>\n",
              "      <td>alfalfa cure covid 19</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>President Trump Asked What He Would Do If He W...</td>\n",
              "      <td>president trump asked would catch coronavirus ...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>States reported 630 deaths. We are still seein...</td>\n",
              "      <td>states reported 630 deaths still seeing solid ...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>This is the sixth time a global health emergen...</td>\n",
              "      <td>sixth time global health emergency declared in...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Low #vitaminD was an independent predictor of ...</td>\n",
              "      <td>low vitamind independent predictor worse progn...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>A common question: why are the cumulative outc...</td>\n",
              "      <td>common question cumulative outcome numbers sma...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>The government should consider bringing in any...</td>\n",
              "      <td>government consider bringing new national lock...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Our daily update is published. We’ve now track...</td>\n",
              "      <td>daily update published tracked 2 9 million tes...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Breakdown of testing: 4 air crew 97 hotel &amp;amp...</td>\n",
              "      <td>breakdown testing 4 air crew 97 hotel amp heal...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>Two interesting correlations:\\n\\n1) Children t...</td>\n",
              "      <td>two interesting correlations 1 children tend w...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>A photo shows a 19-year-old vaccine for canine...</td>\n",
              "      <td>photo shows 19 year old vaccine canine coronav...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>🇰🇼 Assistant Undersecretary for Public Health ...</td>\n",
              "      <td>assistant undersecretary public health affairs...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>An audio file by an alleged worker at a health...</td>\n",
              "      <td>audio file alleged worker health institution r...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>Says the Coronavirus Aid, Relief, and Economic...</td>\n",
              "      <td>says coronavirus aid relief economic security ...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  ... label\n",
              "0    1  ...  real\n",
              "1    2  ...  fake\n",
              "2    3  ...  fake\n",
              "3    4  ...  real\n",
              "4    5  ...  real\n",
              "5    6  ...  real\n",
              "6    7  ...  real\n",
              "7    8  ...  real\n",
              "8    9  ...  real\n",
              "9   10  ...  real\n",
              "10  11  ...  fake\n",
              "11  12  ...  fake\n",
              "12  13  ...  real\n",
              "13  14  ...  fake\n",
              "14  15  ...  fake\n",
              "\n",
              "[15 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 352
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feWHKhcjN_op"
      },
      "source": [
        "test[['id','label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuXcp0WcOQza",
        "outputId": "00003d30-faac-4e2a-95eb-372cff2f5fdb"
      },
      "source": [
        "test['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "real    1109\n",
              "fake    1031\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDlNtveEdxbU"
      },
      "source": [
        "with open('svm(94.62).txt', 'w') as f:\n",
        "  f.write(\"id,label\\n\")\n",
        "  for i in range(len(pred_test)):\n",
        "    id = test['id'][i]\n",
        "    v = pred_test[i]\n",
        "    f.write(\"%d,%s\\n\"%(id, v))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}