{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Constraint-Fake News-(Try 3)))",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1cdQup0boLvBJpMiN5c978hpaaviLMRHZ",
      "authorship_tag": "ABX9TyNVKa9R0kPtHRHDzn97RvrX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcmE1FLhS9PE",
        "outputId": "af90a69b-c40e-44ab-9cea-8f28ffb9b1d7"
      },
      "source": [
        "%%time\r\n",
        "import os\r\n",
        "from glob import glob\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "import json\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import regularizers\r\n",
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "from tensorflow.keras.layers import LSTM,GRU\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.metrics import classification_report \r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\r\n",
        "from sklearn.metrics import average_precision_score,roc_auc_score, roc_curve, precision_recall_curve\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "np.random.seed(42)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.66 s, sys: 334 ms, total: 1.99 s\n",
            "Wall time: 2.71 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2tKLhTotZOV",
        "outputId": "0b7e33b3-aa3a-4cc4-8ad9-04b93350f581"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFfStxsdo8_4"
      },
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-isPOTqtIu2"
      },
      "source": [
        "stops = set(stopwords.words(\"english\"))\r\n",
        "def cleantext(string):\r\n",
        "    text = string.lower().split()\r\n",
        "    text = \" \".join(text)\r\n",
        "    text = re.sub(r\"http(\\S)+\",' ',text)    \r\n",
        "    text = re.sub(r\"www(\\S)+\",' ',text)\r\n",
        "    text = re.sub(r\"&\",' and ',text)  \r\n",
        "    tx = text.replace('&amp',' ')\r\n",
        "    text = re.sub(r\"[^0-9a-zA-Z]+\",' ',text)\r\n",
        "    text = text.split()\r\n",
        "    text = [w for w in text if not w in stops]\r\n",
        "    text = \" \".join(text)\r\n",
        "    return text"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGXpNuzWSfb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8e85d92-9a66-4951-caee-6909eeec81d5"
      },
      "source": [
        "%%time\n",
        "path = \"/content/drive/My Drive/SharedTasksParticipation/SharedTask@Constraint@AAAI2021/\"\n",
        "train_filename= path + \"Constraint_English_Train.xlsx\"\n",
        "val_filename = path + \"Constraint_English_Val .xlsx\"\n",
        "test_filename = path + \"Constraint_English_Test.xlsx\"\n",
        "\n",
        "train = pd.read_excel(train_filename)\n",
        "val = pd.read_excel(val_filename)\n",
        "test = pd.read_excel(test_filename)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 409 ms, sys: 657 µs, total: 410 ms\n",
            "Wall time: 3.69 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS7BJPDiY3gr"
      },
      "source": [
        "train['train_label']= train.label.replace({'real':0,'fake':1})\r\n",
        "val['val_label']= val.label.replace({'real':0,'fake':1})"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRNut988y1u9"
      },
      "source": [
        "train['cleaned'] = train['tweet'].map(lambda x: cleantext(x))\r\n",
        "val['cleaned'] = val['tweet'].map(lambda x: cleantext(x))\r\n",
        "test['cleaned'] = test['tweet'].map(lambda x: cleantext(x))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXFGFQsDQSLt"
      },
      "source": [
        "total_data=pd.concat([train.cleaned, val.cleaned, test.cleaned], axis=0)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "L32nDPntRtyO",
        "outputId": "157a2887-cbac-4297-89b5-08559edd5b89"
      },
      "source": [
        "train"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>train_label</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
              "      <td>real</td>\n",
              "      <td>0</td>\n",
              "      <td>cdc currently reports 99031 deaths general dis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>States reported 1121 deaths a small rise from ...</td>\n",
              "      <td>real</td>\n",
              "      <td>0</td>\n",
              "      <td>states reported 1121 deaths small rise last tu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>politically correct woman almost uses pandemic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
              "      <td>real</td>\n",
              "      <td>0</td>\n",
              "      <td>indiafightscorona 1524 covid testing laborator...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Populous states can generate large case counts...</td>\n",
              "      <td>real</td>\n",
              "      <td>0</td>\n",
              "      <td>populous states generate large case counts loo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6415</th>\n",
              "      <td>6416</td>\n",
              "      <td>A tiger tested positive for COVID-19 please st...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>tiger tested positive covid 19 please stay awa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6416</th>\n",
              "      <td>6417</td>\n",
              "      <td>???Autopsies prove that COVID-19 is??� a blood...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>autopsies prove covid 19 blood clot pneumonia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6417</th>\n",
              "      <td>6418</td>\n",
              "      <td>_A post claims a COVID-19 vaccine has already ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>post claims covid 19 vaccine already developed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6418</th>\n",
              "      <td>6419</td>\n",
              "      <td>Aamir Khan Donate 250 Cr. In PM Relief Cares Fund</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>aamir khan donate 250 cr pm relief cares fund</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6419</th>\n",
              "      <td>6420</td>\n",
              "      <td>It has been 93 days since the last case of COV...</td>\n",
              "      <td>real</td>\n",
              "      <td>0</td>\n",
              "      <td>93 days since last case covid 19 acquired loca...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6420 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                            cleaned\n",
              "0        1  ...  cdc currently reports 99031 deaths general dis...\n",
              "1        2  ...  states reported 1121 deaths small rise last tu...\n",
              "2        3  ...  politically correct woman almost uses pandemic...\n",
              "3        4  ...  indiafightscorona 1524 covid testing laborator...\n",
              "4        5  ...  populous states generate large case counts loo...\n",
              "...    ...  ...                                                ...\n",
              "6415  6416  ...  tiger tested positive covid 19 please stay awa...\n",
              "6416  6417  ...  autopsies prove covid 19 blood clot pneumonia ...\n",
              "6417  6418  ...  post claims covid 19 vaccine already developed...\n",
              "6418  6419  ...      aamir khan donate 250 cr pm relief cares fund\n",
              "6419  6420  ...  93 days since last case covid 19 acquired loca...\n",
              "\n",
              "[6420 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "_6QyyBkVR7gm",
        "outputId": "45f9d310-2073-4a16-dbe6-1dc915d4789c"
      },
      "source": [
        "val"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>val_label</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Chinese converting to Islam after realising th...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>chinese converting islam realising muslim affe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>11 out of 13 people (from the Diamond Princess...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>11 13 people diamond princess cruise ship inti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>COVID-19 Is Caused By A Bacterium, Not Virus A...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>covid 19 caused bacterium virus treated aspirin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Mike Pence in RNC speech praises Donald Trump’...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>mike pence rnc speech praises donald trump cov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>6/10 Sky's @EdConwaySky explains the latest #C...</td>\n",
              "      <td>real</td>\n",
              "      <td>0</td>\n",
              "      <td>6 10 sky edconwaysky explains latest covid19 d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2135</th>\n",
              "      <td>2136</td>\n",
              "      <td>Donald Trump wrongly claimed that New Zealand ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>donald trump wrongly claimed new zealand big s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2136</th>\n",
              "      <td>2137</td>\n",
              "      <td>Current understanding is #COVID19 spreads most...</td>\n",
              "      <td>real</td>\n",
              "      <td>0</td>\n",
              "      <td>current understanding covid19 spreads mostly p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2137</th>\n",
              "      <td>2138</td>\n",
              "      <td>Nothing screams “I am sat around doing fuck al...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>nothing screams sat around fuck lockdown quite...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2138</th>\n",
              "      <td>2139</td>\n",
              "      <td>Birx says COVID-19 outbreak not under control ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>birx says covid 19 outbreak control people move</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2139</th>\n",
              "      <td>2140</td>\n",
              "      <td>Another 4422 new coronavirus cases have been c...</td>\n",
              "      <td>real</td>\n",
              "      <td>0</td>\n",
              "      <td>another 4422 new coronavirus cases confirmed u...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2140 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                            cleaned\n",
              "0        1  ...  chinese converting islam realising muslim affe...\n",
              "1        2  ...  11 13 people diamond princess cruise ship inti...\n",
              "2        3  ...    covid 19 caused bacterium virus treated aspirin\n",
              "3        4  ...  mike pence rnc speech praises donald trump cov...\n",
              "4        5  ...  6 10 sky edconwaysky explains latest covid19 d...\n",
              "...    ...  ...                                                ...\n",
              "2135  2136  ...  donald trump wrongly claimed new zealand big s...\n",
              "2136  2137  ...  current understanding covid19 spreads mostly p...\n",
              "2137  2138  ...  nothing screams sat around fuck lockdown quite...\n",
              "2138  2139  ...    birx says covid 19 outbreak control people move\n",
              "2139  2140  ...  another 4422 new coronavirus cases confirmed u...\n",
              "\n",
              "[2140 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "L5QTGRdwR1M4",
        "outputId": "9e64c608-2b93-4c5b-9fb3-0dd474b1ade2"
      },
      "source": [
        "test"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Our daily update is published. States reported...</td>\n",
              "      <td>real</td>\n",
              "      <td>daily update published states reported 734k te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Alfalfa is the only cure for COVID-19.</td>\n",
              "      <td>fake</td>\n",
              "      <td>alfalfa cure covid 19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>President Trump Asked What He Would Do If He W...</td>\n",
              "      <td>fake</td>\n",
              "      <td>president trump asked would catch coronavirus ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>States reported 630 deaths. We are still seein...</td>\n",
              "      <td>real</td>\n",
              "      <td>states reported 630 deaths still seeing solid ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>This is the sixth time a global health emergen...</td>\n",
              "      <td>real</td>\n",
              "      <td>sixth time global health emergency declared in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2135</th>\n",
              "      <td>2136</td>\n",
              "      <td>#CoronaVirusUpdates: State-wise details of Tot...</td>\n",
              "      <td>real</td>\n",
              "      <td>coronavirusupdates state wise details total co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2136</th>\n",
              "      <td>2137</td>\n",
              "      <td>Tonight 12(midnight) onwards Disaster Manageme...</td>\n",
              "      <td>fake</td>\n",
              "      <td>tonight 12 midnight onwards disaster managemen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2137</th>\n",
              "      <td>2138</td>\n",
              "      <td>296 new cases of #COVID19Nigeria; Plateau-85 E...</td>\n",
              "      <td>real</td>\n",
              "      <td>296 new cases covid19nigeria plateau 85 enugu ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2138</th>\n",
              "      <td>2139</td>\n",
              "      <td>RT @CDCemergency: #DYK? @CDCgov’s One-Stop Sho...</td>\n",
              "      <td>real</td>\n",
              "      <td>rt cdcemergency dyk cdcgov one stop shop covid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2139</th>\n",
              "      <td>2140</td>\n",
              "      <td>More than half of pregnant women recently admi...</td>\n",
              "      <td>real</td>\n",
              "      <td>half pregnant women recently admitted uk hospi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2140 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                            cleaned\n",
              "0        1  ...  daily update published states reported 734k te...\n",
              "1        2  ...                              alfalfa cure covid 19\n",
              "2        3  ...  president trump asked would catch coronavirus ...\n",
              "3        4  ...  states reported 630 deaths still seeing solid ...\n",
              "4        5  ...  sixth time global health emergency declared in...\n",
              "...    ...  ...                                                ...\n",
              "2135  2136  ...  coronavirusupdates state wise details total co...\n",
              "2136  2137  ...  tonight 12 midnight onwards disaster managemen...\n",
              "2137  2138  ...  296 new cases covid19nigeria plateau 85 enugu ...\n",
              "2138  2139  ...  rt cdcemergency dyk cdcgov one stop shop covid...\n",
              "2139  2140  ...  half pregnant women recently admitted uk hospi...\n",
              "\n",
              "[2140 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fVjKbA2SG5P",
        "outputId": "a31515cd-a558-4e52-c32d-2d01181df5cc"
      },
      "source": [
        "total_data"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       cdc currently reports 99031 deaths general dis...\n",
              "1       states reported 1121 deaths small rise last tu...\n",
              "2       politically correct woman almost uses pandemic...\n",
              "3       indiafightscorona 1524 covid testing laborator...\n",
              "4       populous states generate large case counts loo...\n",
              "                              ...                        \n",
              "2135    coronavirusupdates state wise details total co...\n",
              "2136    tonight 12 midnight onwards disaster managemen...\n",
              "2137    296 new cases covid19nigeria plateau 85 enugu ...\n",
              "2138    rt cdcemergency dyk cdcgov one stop shop covid...\n",
              "2139    half pregnant women recently admitted uk hospi...\n",
              "Name: cleaned, Length: 10700, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1Ni0qZwTivJ"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "\r\n",
        "def text_encoding(texts, labels, padding_length):\r\n",
        "  tokenizer = Tokenizer()\r\n",
        "  \r\n",
        "  # Tokenizer is fitted into the texts\r\n",
        "  tokenizer.fit_on_texts(texts)\r\n",
        "\r\n",
        "  # Encoding texts into integer sequences\r\n",
        "  sequences = tokenizer.texts_to_sequences(texts)\r\n",
        "  # Pad sequences\r\n",
        "  corpus = keras.preprocessing.sequence.pad_sequences(sequences, value=0.0,\r\n",
        "                                                      padding='post', maxlen= padding_length)\r\n",
        "\r\n",
        "  return corpus, labels, tokenizer\r\n",
        "\r\n",
        "##\r\n",
        "#max_words = 20000 # Based on number of unique words in the dataset\r\n",
        "padding_length = 100\r\n",
        "corpus, labels, tokenizer = text_encoding(train.cleaned, train.train_label, padding_length)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3Lsr4R6UKUu"
      },
      "source": [
        "train_data, train_labels = corpus, labels"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKA7w7SkUh5q",
        "outputId": "97fff4ea-6038-44b5-fa93-4c75ab1e3546"
      },
      "source": [
        "print(train_data, train_labels)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  69  215  203 ...    0    0    0]\n",
            " [  12   18 6790 ...    0    0    0]\n",
            " [4792 1770  373 ...    0    0    0]\n",
            " ...\n",
            " [ 216  104    1 ...    0    0    0]\n",
            " [2806  899 2685 ...    0    0    0]\n",
            " [1560   42   83 ...    0    0    0]] 0       0\n",
            "1       0\n",
            "2       1\n",
            "3       0\n",
            "4       0\n",
            "       ..\n",
            "6415    1\n",
            "6416    1\n",
            "6417    1\n",
            "6418    1\n",
            "6419    0\n",
            "Name: train_label, Length: 6420, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAHPN3Mb_rmq",
        "outputId": "dc0def56-f28a-4835-e494-bbe695adbd07"
      },
      "source": [
        "word_index = tokenizer.word_index\r\n",
        "vocab_size = len(tokenizer.word_index) + 1\r\n",
        "print(\"Vocabulary Size :\", vocab_size)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size : 14149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG-QHxaN6dma",
        "outputId": "eefeb113-0a2a-498f-f074-65747a5539a3"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\r\n",
        "!unzip glove.6B.zip"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-15 17:13:44--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-02-15 17:13:44--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-02-15 17:13:45--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.02MB/s    in 6m 51s  \n",
            "\n",
            "2021-02-15 17:20:36 (2.00 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbRMnAxP6hH3",
        "outputId": "f1a90ddc-c10e-4fd5-ba86-76351197a4ae"
      },
      "source": [
        "GLOVE_EMB = '/content/glove.6B.100d.txt'\r\n",
        "\r\n",
        "embeddings_index = {}\r\n",
        "\r\n",
        "f = open(GLOVE_EMB)\r\n",
        "for line in f:\r\n",
        "  values = line.split()\r\n",
        "  word = value = values[0]\r\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\r\n",
        "  embeddings_index[word] = coefs\r\n",
        "f.close()\r\n",
        "\r\n",
        "print('Found %s word vectors.' %len(embeddings_index))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAbRCUaO_f_K"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 100))\r\n",
        "for word, i in word_index.items():\r\n",
        "  embedding_vector = embeddings_index.get(word)\r\n",
        "  if embedding_vector is not None:\r\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn1ZqKr0VLly"
      },
      "source": [
        "## Defining Callbacks\r\n",
        "def define_callback():\r\n",
        "  keras.backend.clear_session()\r\n",
        "  accuracy_threshold = .9999\r\n",
        "\r\n",
        "  class myCallback(keras.callbacks.Callback):\r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        if(logs.get('accuracy')>accuracy_threshold):\r\n",
        "          print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\r\n",
        "          self.model.stop_training = True\r\n",
        "\r\n",
        "  acc_callback = myCallback()\r\n",
        "\r\n",
        "  return acc_callback\r\n",
        "\r\n",
        "# Define Checkpoint\r\n",
        "def define_checkpoint():\r\n",
        "  filepath = \"ModelOnOurData.h5\"\r\n",
        "  checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True, save_weights_only=False, mode='max')\r\n",
        "  return checkpoint"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbjBnr2eVwbI"
      },
      "source": [
        "from tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, Dropout\r\n",
        "from tensorflow.keras.layers import SpatialDropout1D\r\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA-QcHtcVVPb"
      },
      "source": [
        "# Create Model\r\n",
        "def create_model(embedding_dim):\r\n",
        "  keras.backend.clear_session()\r\n",
        "\r\n",
        "  model = keras.models.Sequential([\r\n",
        "      keras.layers.Embedding(vocab_size, embedding_dim, input_length = padding_length),\r\n",
        "      #keras.layers.Conv1D(64, 5, activation='relu'),\r\n",
        "      #keras.layers.MaxPooling1D(5),\r\n",
        "      #keras.layers.Bidirectional(LSTM(32, dropout=0.4)),\r\n",
        "      #keras.layers.Dense(64, activation='relu'),\r\n",
        "      #keras.layers.Dropout(0.5),\r\n",
        "      keras.layers.Dense(64, activation='relu'),\r\n",
        "      keras.layers.Flatten(),\r\n",
        "      keras.layers.Dense(2, activation = 'softmax')\r\n",
        "  ])\r\n",
        "\r\n",
        "  model.summary()\r\n",
        "  return model\r\n",
        "\r\n",
        "\r\n",
        "# Compile Model\r\n",
        "def compile_model(model):\r\n",
        "  model.compile(optimizer=Adam(learning_rate=0.0001),\r\n",
        "                  loss='sparse_categorical_crossentropy',\r\n",
        "                  metrics='accuracy')\r\n",
        "  return model\r\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kQw1ayAXFbo",
        "outputId": "6a693761-857a-48f4-c3f3-b3bcff88a68f"
      },
      "source": [
        "%%time\r\n",
        "## Callbacks are really important \r\n",
        "\r\n",
        "def run_callback_list():\r\n",
        "  acc_callback = define_callback()\r\n",
        "  checkpoint = define_checkpoint()\r\n",
        "  return [acc_callback, checkpoint] \r\n",
        "\r\n",
        "callback_list = run_callback_list()\r\n",
        "\r\n",
        "def run_model():\r\n",
        "    embedding_dim = 100\r\n",
        "    model = create_model(embedding_dim)\r\n",
        "    model = compile_model(model)\r\n",
        "    return model\r\n",
        "\r\n",
        "## Create, Compile and Visualize the model\r\n",
        "cnn_lstm_model = run_model() ## "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 100)          1414900   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100, 64)           6464      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 12802     \n",
            "=================================================================\n",
            "Total params: 1,434,166\n",
            "Trainable params: 1,434,166\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 450 ms, sys: 334 ms, total: 784 ms\n",
            "Wall time: 5.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukDreeN2CFJF"
      },
      "source": [
        "cnn_lstm_model.layers[0].set_weights([embedding_matrix])\r\n",
        "cnn_lstm_model.layers[0].trainable = False"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ej4j7KCYSdX",
        "outputId": "8887d55c-a218-494d-b4cb-60ec94562c64"
      },
      "source": [
        "cnn_lstm_model_history = cnn_lstm_model.fit(train_data,\r\n",
        "                              train_labels,\r\n",
        "                              epochs = 50,\r\n",
        "                              batch_size = 64,\r\n",
        "                              verbose = 1,\r\n",
        "                              validation_split = 0.15,\r\n",
        "                              callbacks = callback_list)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "86/86 [==============================] - 3s 16ms/step - loss: 0.6305 - accuracy: 0.6410 - val_loss: 0.5497 - val_accuracy: 0.7456\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.74559, saving model to ModelOnOurData.h5\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.5337 - accuracy: 0.7508 - val_loss: 0.5012 - val_accuracy: 0.7632\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.74559 to 0.76324, saving model to ModelOnOurData.h5\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.4785 - accuracy: 0.7734 - val_loss: 0.4595 - val_accuracy: 0.7913\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.76324 to 0.79128, saving model to ModelOnOurData.h5\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.4247 - accuracy: 0.8131 - val_loss: 0.4235 - val_accuracy: 0.8120\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.79128 to 0.81205, saving model to ModelOnOurData.h5\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.3885 - accuracy: 0.8371 - val_loss: 0.3921 - val_accuracy: 0.8287\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.81205 to 0.82866, saving model to ModelOnOurData.h5\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.3464 - accuracy: 0.8556 - val_loss: 0.3665 - val_accuracy: 0.8359\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.82866 to 0.83593, saving model to ModelOnOurData.h5\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.3134 - accuracy: 0.8757 - val_loss: 0.3455 - val_accuracy: 0.8432\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.83593 to 0.84320, saving model to ModelOnOurData.h5\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 1s 16ms/step - loss: 0.2911 - accuracy: 0.8858 - val_loss: 0.3293 - val_accuracy: 0.8546\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.84320 to 0.85462, saving model to ModelOnOurData.h5\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.2700 - accuracy: 0.8988 - val_loss: 0.3158 - val_accuracy: 0.8650\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.85462 to 0.86501, saving model to ModelOnOurData.h5\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.2461 - accuracy: 0.9055 - val_loss: 0.3049 - val_accuracy: 0.8660\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.86501 to 0.86604, saving model to ModelOnOurData.h5\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.2238 - accuracy: 0.9151 - val_loss: 0.2958 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.86604 to 0.87435, saving model to ModelOnOurData.h5\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.2166 - accuracy: 0.9141 - val_loss: 0.2868 - val_accuracy: 0.8795\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.87435 to 0.87954, saving model to ModelOnOurData.h5\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.2015 - accuracy: 0.9244 - val_loss: 0.2798 - val_accuracy: 0.8889\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.87954 to 0.88889, saving model to ModelOnOurData.h5\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.1823 - accuracy: 0.9299 - val_loss: 0.2738 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.88889 to 0.89408, saving model to ModelOnOurData.h5\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.1776 - accuracy: 0.9332 - val_loss: 0.2677 - val_accuracy: 0.8962\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.89408 to 0.89616, saving model to ModelOnOurData.h5\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.1631 - accuracy: 0.9410 - val_loss: 0.2625 - val_accuracy: 0.8993\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.89616 to 0.89927, saving model to ModelOnOurData.h5\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.1561 - accuracy: 0.9450 - val_loss: 0.2593 - val_accuracy: 0.9003\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.89927 to 0.90031, saving model to ModelOnOurData.h5\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.1497 - accuracy: 0.9475 - val_loss: 0.2547 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.90031 to 0.90654, saving model to ModelOnOurData.h5\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.1427 - accuracy: 0.9521 - val_loss: 0.2497 - val_accuracy: 0.9055\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.90654\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.1276 - accuracy: 0.9593 - val_loss: 0.2468 - val_accuracy: 0.9065\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.90654\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.1287 - accuracy: 0.9591 - val_loss: 0.2444 - val_accuracy: 0.9107\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.90654 to 0.91070, saving model to ModelOnOurData.h5\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 1s 16ms/step - loss: 0.1122 - accuracy: 0.9640 - val_loss: 0.2417 - val_accuracy: 0.9117\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.91070 to 0.91173, saving model to ModelOnOurData.h5\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.1099 - accuracy: 0.9670 - val_loss: 0.2389 - val_accuracy: 0.9076\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91173\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.1033 - accuracy: 0.9653 - val_loss: 0.2367 - val_accuracy: 0.9107\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91173\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.0923 - accuracy: 0.9701 - val_loss: 0.2351 - val_accuracy: 0.9097\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91173\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.0903 - accuracy: 0.9717 - val_loss: 0.2338 - val_accuracy: 0.9180\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.91173 to 0.91796, saving model to ModelOnOurData.h5\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.0803 - accuracy: 0.9788 - val_loss: 0.2326 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91796\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0794 - accuracy: 0.9778 - val_loss: 0.2311 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91796\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.0750 - accuracy: 0.9797 - val_loss: 0.2315 - val_accuracy: 0.9180\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91796\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0692 - accuracy: 0.9812 - val_loss: 0.2295 - val_accuracy: 0.9169\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91796\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0663 - accuracy: 0.9855 - val_loss: 0.2290 - val_accuracy: 0.9148\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91796\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0602 - accuracy: 0.9859 - val_loss: 0.2286 - val_accuracy: 0.9169\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91796\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0601 - accuracy: 0.9868 - val_loss: 0.2285 - val_accuracy: 0.9148\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91796\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0552 - accuracy: 0.9863 - val_loss: 0.2282 - val_accuracy: 0.9159\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91796\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0490 - accuracy: 0.9891 - val_loss: 0.2285 - val_accuracy: 0.9169\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91796\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0484 - accuracy: 0.9906 - val_loss: 0.2288 - val_accuracy: 0.9180\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91796\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0477 - accuracy: 0.9880 - val_loss: 0.2292 - val_accuracy: 0.9190\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.91796 to 0.91900, saving model to ModelOnOurData.h5\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0435 - accuracy: 0.9898 - val_loss: 0.2296 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.91900 to 0.92004, saving model to ModelOnOurData.h5\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0440 - accuracy: 0.9902 - val_loss: 0.2306 - val_accuracy: 0.9211\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.92004 to 0.92108, saving model to ModelOnOurData.h5\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.0420 - accuracy: 0.9927 - val_loss: 0.2303 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.92108\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 1s 15ms/step - loss: 0.0336 - accuracy: 0.9941 - val_loss: 0.2305 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.92108 to 0.92523, saving model to ModelOnOurData.h5\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0375 - accuracy: 0.9913 - val_loss: 0.2322 - val_accuracy: 0.9232\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.92523\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0331 - accuracy: 0.9936 - val_loss: 0.2317 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.92523\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0300 - accuracy: 0.9952 - val_loss: 0.2340 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.92523\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0277 - accuracy: 0.9947 - val_loss: 0.2346 - val_accuracy: 0.9263\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.92523 to 0.92627, saving model to ModelOnOurData.h5\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0262 - accuracy: 0.9953 - val_loss: 0.2349 - val_accuracy: 0.9263\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.92627\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0244 - accuracy: 0.9969 - val_loss: 0.2362 - val_accuracy: 0.9273\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.92627 to 0.92731, saving model to ModelOnOurData.h5\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0248 - accuracy: 0.9960 - val_loss: 0.2383 - val_accuracy: 0.9273\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.92731\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0226 - accuracy: 0.9974 - val_loss: 0.2389 - val_accuracy: 0.9232\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.92731\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 1s 14ms/step - loss: 0.0217 - accuracy: 0.9977 - val_loss: 0.2399 - val_accuracy: 0.9263\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.92731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcyXEMxC2kJE",
        "outputId": "009d178c-e402-4ff3-f3de-16f4a9cb073b"
      },
      "source": [
        "val_sequences = tokenizer.texts_to_sequences(val.cleaned)\r\n",
        "print(val_sequences[0:10])\r\n",
        "val_data = keras.preprocessing.sequence.pad_sequences(val_sequences, value=0.0,\r\n",
        "                                                      padding='post', maxlen= padding_length)\r\n",
        "val_labels = val['val_label']\r\n",
        "\r\n",
        "print(val_data[:5], val_data.shape)\r\n",
        "print(val_labels[:5], val_labels.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[234, 9592, 4338, 828, 424, 4, 73], [106, 239, 8, 5084, 3991, 1683, 1347, 41, 236, 9, 1116, 1126, 16, 40, 346, 12], [1, 2, 392, 2526, 29, 859, 5044], [2014, 2032, 7757, 4078, 10896, 178, 43, 1, 2, 3937, 2174, 1010, 2457, 68, 23, 3636], [55, 63, 968, 1053, 110, 5, 38, 67, 2639, 77, 4, 38], [24, 1515, 135, 66, 959, 374, 851, 236, 44, 1971, 44, 1799, 637, 311, 42, 298, 3796, 3877, 2468, 4320, 5694], [27, 7, 24, 449, 5, 575, 1375, 290, 13, 31, 445, 57, 502, 6074, 75, 66, 17, 339, 371, 204, 122, 12, 375, 1700, 416, 156, 132], [39, 5, 297, 10464, 4462, 2419, 260, 166, 111, 8, 3791], [70, 262, 6100, 1111, 5572, 257, 931, 2911, 18, 1588, 2084, 315, 107, 3914, 2809, 248, 75], [2497, 448, 2176, 2420, 35, 284, 301]]\n",
            "[[  234  9592  4338   828   424     4    73     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]\n",
            " [  106   239     8  5084  3991  1683  1347    41   236     9  1116  1126\n",
            "     16    40   346    12     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]\n",
            " [    1     2   392  2526    29   859  5044     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]\n",
            " [ 2014  2032  7757  4078 10896   178    43     1     2  3937  2174  1010\n",
            "   2457    68    23  3636     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]\n",
            " [   55    63   968  1053   110     5    38    67  2639    77     4    38\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]] (2140, 100)\n",
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: val_label, dtype: int64 (2140,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdJckS8juG3F",
        "outputId": "de5b60f0-44da-4e2c-b670-4ea8b5960d42"
      },
      "source": [
        "cnn_lstm_model=load_model(\"/content/ModelOnOurData.h5\")\r\n",
        "val_ls, val_acc = cnn_lstm_model.evaluate(val_data, val_labels)\r\n",
        "#print(val_labels)\r\n",
        "#print(val_ls, val_acc)\r\n",
        "pred = np.argmax(cnn_lstm_model.predict(val_data), axis=-1)\r\n",
        "#print(pred)\r\n",
        "print(confusion_matrix(pred, val_labels))\r\n",
        "#plot_confusion_matrix(confusion_matrix(val['label'],pred),target_names=['real','fake'], normalize = False, \\\r\n",
        "                      #title = 'Confusion matix of SVM on val data')\r\n",
        "\r\n",
        "\r\n",
        "#svm_val_misclass_df = val_ori[pred!=val['label']]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "67/67 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 0.9220\n",
            "[[1040   87]\n",
            " [  80  933]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaW6HiKJPN7f"
      },
      "source": [
        "# Prediction on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdcsqpM9LNIV",
        "outputId": "a270e5e1-fc47-4bb4-cf78-b1c8d48b1e28"
      },
      "source": [
        "test_sequences = tokenizer.texts_to_sequences(test.cleaned)\r\n",
        "print(test_sequences[0:10])\r\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_sequences, value=0.0,\r\n",
        "                                                      padding='post', maxlen= padding_length)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[48, 34, 97, 12, 18, 9, 8531, 6, 3, 9714, 10, 251, 223, 1386, 2716, 80, 86, 83, 298, 406], [134, 1, 2], [68, 43, 633, 164, 2397, 4, 309, 4], [12, 18, 10, 113, 1415, 1972, 156, 984, 79, 105, 1879, 3011, 311, 42, 1649, 1530, 316, 69, 1498, 1692, 1879, 127, 86, 30, 79, 105, 1191], [3631, 86, 328, 20, 437, 1532, 535, 20, 2547, 1918, 354, 141], [292, 7603, 3401, 1562, 32, 1, 2], [704, 1785, 493, 3711, 84, 1948, 251, 3711, 84, 12, 25, 251, 12, 25, 493, 1540, 10360, 23, 493, 5099, 251], [67, 1692, 351, 6, 156, 52, 693, 3735, 1706, 35, 2200, 539, 1208], [48, 34, 97, 310, 13, 81, 61, 9, 62, 18, 183, 83, 139, 11, 214, 180, 9, 23, 203, 12, 25, 9, 53], [576, 19, 37, 536, 2824, 2100, 1287, 17, 20, 295, 228, 2604, 945, 1287, 4115, 17, 13, 9167, 1405, 687, 236, 9, 855, 251, 4115, 13085, 926, 17, 2491, 261, 236]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir0R6mpKMdPd"
      },
      "source": [
        "pred= np.argmax(cnn_lstm_model.predict(test_data), axis=-1)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZebMSV6sNMrC"
      },
      "source": [
        "jongu = pd.DataFrame(pred, columns=['ll'])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "YRKZW2wiNdRQ",
        "outputId": "58d7907e-7544-4567-ff46-66328ffd3416"
      },
      "source": [
        "jongu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ll</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2135</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2136</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2137</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2138</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2139</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2140 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      ll\n",
              "0      0\n",
              "1      1\n",
              "2      1\n",
              "3      0\n",
              "4      0\n",
              "...   ..\n",
              "2135   0\n",
              "2136   0\n",
              "2137   0\n",
              "2138   0\n",
              "2139   1\n",
              "\n",
              "[2140 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 350
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EhTUvIRMoMf"
      },
      "source": [
        "test['label']= jongu.ll.replace({0:'real',1:'fake'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "fRDSrB3rNKam",
        "outputId": "6ef06cab-3768-47a6-8835-ab05ca2cf36e"
      },
      "source": [
        "test.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Our daily update is published. States reported...</td>\n",
              "      <td>daily update published states reported 734k te...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Alfalfa is the only cure for COVID-19.</td>\n",
              "      <td>alfalfa cure covid 19</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>President Trump Asked What He Would Do If He W...</td>\n",
              "      <td>president trump asked would catch coronavirus ...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>States reported 630 deaths. We are still seein...</td>\n",
              "      <td>states reported 630 deaths still seeing solid ...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>This is the sixth time a global health emergen...</td>\n",
              "      <td>sixth time global health emergency declared in...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Low #vitaminD was an independent predictor of ...</td>\n",
              "      <td>low vitamind independent predictor worse progn...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>A common question: why are the cumulative outc...</td>\n",
              "      <td>common question cumulative outcome numbers sma...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>The government should consider bringing in any...</td>\n",
              "      <td>government consider bringing new national lock...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Our daily update is published. We’ve now track...</td>\n",
              "      <td>daily update published tracked 2 9 million tes...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Breakdown of testing: 4 air crew 97 hotel &amp;amp...</td>\n",
              "      <td>breakdown testing 4 air crew 97 hotel amp heal...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>Two interesting correlations:\\n\\n1) Children t...</td>\n",
              "      <td>two interesting correlations 1 children tend w...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>A photo shows a 19-year-old vaccine for canine...</td>\n",
              "      <td>photo shows 19 year old vaccine canine coronav...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>🇰🇼 Assistant Undersecretary for Public Health ...</td>\n",
              "      <td>assistant undersecretary public health affairs...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>An audio file by an alleged worker at a health...</td>\n",
              "      <td>audio file alleged worker health institution r...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>Says the Coronavirus Aid, Relief, and Economic...</td>\n",
              "      <td>says coronavirus aid relief economic security ...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  ... label\n",
              "0    1  ...  real\n",
              "1    2  ...  fake\n",
              "2    3  ...  fake\n",
              "3    4  ...  real\n",
              "4    5  ...  real\n",
              "5    6  ...  real\n",
              "6    7  ...  real\n",
              "7    8  ...  real\n",
              "8    9  ...  real\n",
              "9   10  ...  real\n",
              "10  11  ...  fake\n",
              "11  12  ...  fake\n",
              "12  13  ...  real\n",
              "13  14  ...  fake\n",
              "14  15  ...  fake\n",
              "\n",
              "[15 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 352
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feWHKhcjN_op"
      },
      "source": [
        "test[['id','label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuXcp0WcOQza",
        "outputId": "00003d30-faac-4e2a-95eb-372cff2f5fdb"
      },
      "source": [
        "test['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "real    1109\n",
              "fake    1031\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDlNtveEdxbU"
      },
      "source": [
        "with open('svm(94.62).txt', 'w') as f:\n",
        "  f.write(\"id,label\\n\")\n",
        "  for i in range(len(pred_test)):\n",
        "    id = test['id'][i]\n",
        "    v = pred_test[i]\n",
        "    f.write(\"%d,%s\\n\"%(id, v))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}